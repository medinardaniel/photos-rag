{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to MongoDB Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new CSV file that contains image descriptions and image attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in image_descriptions: 556\n",
      "Number of rows in photo_metadata: 555\n"
     ]
    }
   ],
   "source": [
    "# load image_descriptions.csv\n",
    "image_descriptions = pd.read_csv('output/image_descriptions.csv')\n",
    "print('Number of rows in image_descriptions:', image_descriptions.shape[0])\n",
    "\n",
    "# load photo_metadata.csv\n",
    "photo_metadata = pd.read_csv('output/photo_metadata.csv')\n",
    "print('Number of rows in photo_metadata:', photo_metadata.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in merged dataframe: 545\n"
     ]
    }
   ],
   "source": [
    "# add the columbs from photo_metadata to image_descriptions on the 'filename' column\n",
    "# Adjust filenames to ensure consistency (all as .jpeg)\n",
    "photo_metadata['filename'] = photo_metadata['filename'].str.replace('.jpg', '.jpeg', regex=False)\n",
    "image_descriptions['filename'] = image_descriptions['filename'].str.replace('.jpg', '.jpeg', regex=False)\n",
    "\n",
    "# Merge the dataframes again after adjusting the filenames\n",
    "merged = pd.merge(image_descriptions, photo_metadata, on='filename')\n",
    "print('Number of rows in merged dataframe:', merged.shape[0])\n",
    "\n",
    "# save the merged dataframe to a new csv file in 'output' folder\n",
    "merged.to_csv('output/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description</th>\n",
       "      <th>people</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2662f4ba-ff02-4175-b562-f27b01d1062a.jpeg</td>\n",
       "      <td>The image shows three individuals posing toget...</td>\n",
       "      <td>Juan Daniel (Man), Kika (Woman), Tia Icha (Woman)</td>\n",
       "      <td>Perímetro Urbano Barranquilla, Atlántico, Colo...</td>\n",
       "      <td>2024-01-01 15:39:42-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe01fa69-6df1-48b8-80a7-eee303558bdd.jpeg</td>\n",
       "      <td>In the image, there are two people posing for ...</td>\n",
       "      <td>Graciela (Woman), Pipe (Man)</td>\n",
       "      <td>Seattle, Washington, United States</td>\n",
       "      <td>2022-07-04 17:54:15-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a36c2180-eb5c-40a1-8dd7-a950c226a0dd.jpeg</td>\n",
       "      <td>In the image, there are three young men close ...</td>\n",
       "      <td>Daniel (Man), Javier (Man), Santiago (Man)</td>\n",
       "      <td>Ann Arbor, Michigan, United States</td>\n",
       "      <td>2022-04-09 23:58:02-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_2008.jpeg</td>\n",
       "      <td>This image features a parking lot situated in ...</td>\n",
       "      <td></td>\n",
       "      <td>Washington, United States</td>\n",
       "      <td>2022-06-26 14:00:10.604301-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_0824.jpeg</td>\n",
       "      <td>In this image, we see a man and a woman seated...</td>\n",
       "      <td>Will (Man)</td>\n",
       "      <td>Ann Arbor, Michigan, United States</td>\n",
       "      <td>2022-04-01 01:22:35.760919-04:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename  \\\n",
       "0  2662f4ba-ff02-4175-b562-f27b01d1062a.jpeg   \n",
       "1  fe01fa69-6df1-48b8-80a7-eee303558bdd.jpeg   \n",
       "2  a36c2180-eb5c-40a1-8dd7-a950c226a0dd.jpeg   \n",
       "3                              IMG_2008.jpeg   \n",
       "4                              IMG_0824.jpeg   \n",
       "\n",
       "                                         description  \\\n",
       "0  The image shows three individuals posing toget...   \n",
       "1  In the image, there are two people posing for ...   \n",
       "2  In the image, there are three young men close ...   \n",
       "3  This image features a parking lot situated in ...   \n",
       "4  In this image, we see a man and a woman seated...   \n",
       "\n",
       "                                              people  \\\n",
       "0  Juan Daniel (Man), Kika (Woman), Tia Icha (Woman)   \n",
       "1                       Graciela (Woman), Pipe (Man)   \n",
       "2         Daniel (Man), Javier (Man), Santiago (Man)   \n",
       "3                                                      \n",
       "4                                         Will (Man)   \n",
       "\n",
       "                                            location  \\\n",
       "0  Perímetro Urbano Barranquilla, Atlántico, Colo...   \n",
       "1                 Seattle, Washington, United States   \n",
       "2                 Ann Arbor, Michigan, United States   \n",
       "3                          Washington, United States   \n",
       "4                 Ann Arbor, Michigan, United States   \n",
       "\n",
       "                               date  \n",
       "0         2024-01-01 15:39:42-05:00  \n",
       "1         2022-07-04 17:54:15-07:00  \n",
       "2         2022-04-09 23:58:02-04:00  \n",
       "3  2022-06-26 14:00:10.604301-07:00  \n",
       "4  2022-04-01 01:22:35.760919-04:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data.csv\n",
    "data = pd.read_csv('output/data.csv')\n",
    "\n",
    "# replace NaN values with empty strings\n",
    "data = data.fillna('')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2662f4ba-ff02-4175-b562-f27b01d1062a.jpeg</td>\n",
       "      <td>People: Juan Daniel (Man), Kika (Woman), Tia I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe01fa69-6df1-48b8-80a7-eee303558bdd.jpeg</td>\n",
       "      <td>People: Graciela (Woman), Pipe (Man)\\n Locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a36c2180-eb5c-40a1-8dd7-a950c226a0dd.jpeg</td>\n",
       "      <td>People: Daniel (Man), Javier (Man), Santiago (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_2008.jpeg</td>\n",
       "      <td>People: \\n Location: Washington, United States...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_0824.jpeg</td>\n",
       "      <td>People: Will (Man)\\n Location: Ann Arbor, Mich...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename  \\\n",
       "0  2662f4ba-ff02-4175-b562-f27b01d1062a.jpeg   \n",
       "1  fe01fa69-6df1-48b8-80a7-eee303558bdd.jpeg   \n",
       "2  a36c2180-eb5c-40a1-8dd7-a950c226a0dd.jpeg   \n",
       "3                              IMG_2008.jpeg   \n",
       "4                              IMG_0824.jpeg   \n",
       "\n",
       "                                                text  \n",
       "0  People: Juan Daniel (Man), Kika (Woman), Tia I...  \n",
       "1  People: Graciela (Woman), Pipe (Man)\\n Locatio...  \n",
       "2  People: Daniel (Man), Javier (Man), Santiago (...  \n",
       "3  People: \\n Location: Washington, United States...  \n",
       "4  People: Will (Man)\\n Location: Ann Arbor, Mich...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe that contains description, people, location, date in a string for each filename\n",
    "data_dict = {}\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    filename = row['filename']\n",
    "    description = row['description']\n",
    "    people = row['people']\n",
    "    location = row['location']\n",
    "    date = row['date']\n",
    "    text = f\"People: {people}\\n Location: {location}\\n Date: {date}\\n Description: {description}\"\n",
    "    data_dict[filename] = text\n",
    "\n",
    "# create a dataframe from the dictionary\n",
    "data_df = pd.DataFrame(data_dict.items(), columns=['filename', 'text'])\n",
    "\n",
    "# save the dataframe to a new csv file in 'output' folder\n",
    "data_df.to_csv('output/data_text.csv', index=False)\n",
    "\n",
    "data_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_text(df, tokenizer, model):\n",
    "    text = df['text']\n",
    "    tokenized_text = tokenizer(text.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    return tokenized_text\n",
    "\n",
    "tokenized_text = tokenize_text(data_df, tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gradient calculations for efficiency\n",
    "with torch.no_grad():\n",
    "    # Get model outputs\n",
    "    outputs = model(**tokenized_text)\n",
    "\n",
    "# The 'outputs' is a tuple where the first item contains the last hidden states\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([545, 309, 768])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embeddings to MongoDB Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "uri = os.getenv('MONGODB_URI')\n",
    "# Connect to the MongoDB client\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Select the database\n",
    "db = client['photo-rag-db']\n",
    "\n",
    "# Select the collection\n",
    "collection_emb = db['photo-embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = data_df['filename'].to_list()\n",
    "texts = data_df['text'].to_list()\n",
    "documents = []\n",
    "\n",
    "# if database is not empty, drop all documents\n",
    "if collection_emb.count_documents({}) > 0:\n",
    "    collection_emb.drop()\n",
    "\n",
    "for filename, text in zip(filenames, texts):\n",
    "    # tokenize text\n",
    "    tokenized_text = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get model outputs\n",
    "        outputs = model(**tokenized_text)\n",
    "    \n",
    "    # extract the last hidden states\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    # calculate the mean of the last hidden states\n",
    "    mean_embedding = torch.mean(last_hidden_states, dim=1).tolist()[0]\n",
    "\n",
    "    # prepare the document\n",
    "    document = {'filename': filename, 'embedding': mean_embedding}\n",
    "\n",
    "    # add to the batch\n",
    "    documents.append(document)\n",
    "\n",
    "# insert documents in batch\n",
    "if documents:\n",
    "    collection_emb.insert_many(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Image-Description data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the MongoDB client, select database and collection\n",
    "client = MongoClient(uri)\n",
    "db = client['photo-rag-db']\n",
    "collection_desc = db['photo-descriptions']\n",
    "\n",
    "# declare list of filenames and descriptions\n",
    "data_text_df = pd.read_csv('output/data_text.csv')\n",
    "filenames = data_text_df['filename'].to_list()\n",
    "descriptions = data_text_df['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if collection_desc is not empty, drop all documents\n",
    "if collection_desc.count_documents({}) > 0:\n",
    "    collection_desc.drop()\n",
    "\n",
    "for filename, description in zip(filenames, descriptions):\n",
    "    # Insert the data into the collection\n",
    "    collection_desc.insert_one({\n",
    "        'filename': filename,\n",
    "        'description': description\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
